# -*- coding: utf-8 -*-
"""evaluate_results.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eB_jXvztQ4xCCzjw2VHhEw4zPxCPMDjj
"""

from google.colab import drive
drive.mount('/content/drive' )

import numpy as np
import gc
import sys
import os
import pandas as pd
sys.path.append('/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/tools')
sys.path.append('/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification')
from tools_benchmark import  compute_bias_metrics_for_model, calculate_overall_auc,get_final_metric
from tools_evaluate_model import evaluate

test_public_df = pd.read_csv("/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/data/test_public_cleared.csv")
#test_public_df = test_public_df.loc[:, ['toxicity','comment_text']  + IDENTITY_COLUMNS ].dropna()[:1000]
test_private_df = pd.read_csv("/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/data/test_private_cleared.csv")
#test_private_df = test_private_df.loc[:, ['toxicity', 'comment_text'] + IDENTITY_COLUMNS ].dropna()[:1000]

def get_predictions(modelPATH):
  y_public_pred = np.load(modelPATH + '/y_public_pred.npy')
  y_private_pred = np.load(modelPATH + '/y_private_pred.npy')

  return y_public_pred , y_private_pred

"""# BERT"""

PATH = '/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/models/BERT/BERT-with-max-avg-pool/'
versions = sorted(os.listdir(PATH))
for version in versions[:4]:
  y_public_pred ,y_private_pred =  get_predictions(os.path.join(PATH,version))
  evaluate(y_public_pred,y_private_pred, test_public_df, test_private_df,'BERT/BERT-with-max-avg-pool/' + version, version )

PATH = '/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/models/RoBERTa/RoBERTa-with-max-avg-pool/'
versions = sorted(os.listdir(PATH))
for version in versions[:4]:
  y_public_pred ,y_private_pred =  get_predictions(os.path.join(PATH,version))
  evaluate(y_public_pred,y_private_pred, test_public_df, test_private_df,'RoBERTa/RoBERTa-with-max-avg-pool/' + version, version )

PATH = '/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/models/gpt2/gpt2-with-max-avg-pool/'
versions = sorted(os.listdir(PATH))
for version in versions[:4]:
  y_public_pred ,y_private_pred =  get_predictions(os.path.join(PATH,version))
  evaluate(y_public_pred,y_private_pred, test_public_df, test_private_df,'gpt2/gpt2-with-max-avg-pool/' + version, version )

PATH = '/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/models/BiLSTM/'
versions = sorted(os.listdir(PATH))
for version in versions:
  y_public_pred ,y_private_pred =  get_predictions(os.path.join(PATH,version))
  evaluate(y_public_pred,y_private_pred, test_public_df, test_private_df,'BiLSTM/' + version, version )

PATH = '/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/models/BiGRU/'
versions = sorted(os.listdir(PATH))
for version in versions:
  y_public_pred ,y_private_pred =  get_predictions(os.path.join(PATH,version))
  evaluate(y_public_pred,y_private_pred, test_public_df, test_private_df,'BiGRU/' + version, version )

PATH = '/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/models/TextCNN/'
versions = sorted(os.listdir(PATH))
version = versions[1]
y_public_pred ,y_private_pred =  get_predictions(os.path.join(PATH,version))
evaluate(y_public_pred,y_private_pred, test_public_df, test_private_df,'TextCNN/' + version, version )

