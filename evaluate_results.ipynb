{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evaluate_results.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXLICNcMq+3rmwXHIIOn6F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CoGian/Detection-of-toxic-comments-and-minimization-of-unintended-model-bias-using-neural-networks/blob/master/evaluate_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx0vjXiD-3D-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "9d4345a0-1949-4fe9-aad5-46e9cb4f2287"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn7QbBzF-9DC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import gc\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "sys.path.append('/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/tools')\n",
        "sys.path.append('/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification')\n",
        "from tools_benchmark import  compute_bias_metrics_for_model, calculate_overall_auc,get_final_metric\n",
        "from tools_evaluate_model import evaluate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-NkIB3h--qQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_public_df = pd.read_csv(\"/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/data/test_public_cleared.csv\")\n",
        "#test_public_df = test_public_df.loc[:, ['toxicity','comment_text']  + IDENTITY_COLUMNS ].dropna()[:1000]\n",
        "test_private_df = pd.read_csv(\"/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/data/test_private_cleared.csv\")\n",
        "#test_private_df = test_private_df.loc[:, ['toxicity', 'comment_text'] + IDENTITY_COLUMNS ].dropna()[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KaolqPF_FUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions(modelPATH):\n",
        "  y_public_pred = np.load(modelPATH + '/y_public_pred.npy')\n",
        "  y_private_pred = np.load(modelPATH + '/y_private_pred.npy')\n",
        "\n",
        "  return y_public_pred , y_private_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwtfF0Eu_byi",
        "colab_type": "text"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfloHdUk_Y4Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "04273a7b-4cfa-443a-c376-7105e513ca1e"
      },
      "source": [
        "PATH = '/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/models/BERT/BERT-with-max-avg-pool/'\n",
        "versions = sorted(os.listdir(PATH))\n",
        "for version in versions[:4]:\n",
        "  y_public_pred ,y_private_pred =  get_predictions(os.path.join(PATH,version))\n",
        "  evaluate(y_public_pred,y_private_pred, test_public_df, test_private_df,'BERT/BERT-with-max-avg-pool/' + version, version )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on public test: 0.951675\n",
            "Accuracy on private test: 0.952106\n",
            "Public AUC score : 0.929423\n",
            "Private AUC score : 0.930776\n",
            "Accuracy on public test: 0.953381\n",
            "Accuracy on private test: 0.953206\n",
            "Public AUC score : 0.929641\n",
            "Private AUC score : 0.930286\n",
            "Accuracy on public test: 0.952322\n",
            "Accuracy on private test: 0.951942\n",
            "Public AUC score : 0.927536\n",
            "Private AUC score : 0.928246\n",
            "Accuracy on public test: 0.953617\n",
            "Accuracy on private test: 0.953956\n",
            "Public AUC score : 0.927782\n",
            "Private AUC score : 0.927363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN2NNLPb_yaA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "0f1558e4-1857-4669-8ca8-5184806d76ff"
      },
      "source": [
        "PATH = '/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/models/RoBERTa/RoBERTa-with-max-avg-pool/'\n",
        "versions = sorted(os.listdir(PATH))\n",
        "for version in versions[:4]:\n",
        "  y_public_pred ,y_private_pred =  get_predictions(os.path.join(PATH,version))\n",
        "  evaluate(y_public_pred,y_private_pred, test_public_df, test_private_df,'RoBERTa/RoBERTa-with-max-avg-pool/' + version, version )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on public test: 0.941112\n",
            "Accuracy on private test: 0.941574\n",
            "Public AUC score : 0.932793\n",
            "Private AUC score : 0.933586\n",
            "Accuracy on public test: 0.945150\n",
            "Accuracy on private test: 0.944605\n",
            "Public AUC score : 0.934961\n",
            "Private AUC score : 0.936170\n",
            "Accuracy on public test: 0.949558\n",
            "Accuracy on private test: 0.949990\n",
            "Public AUC score : 0.932885\n",
            "Private AUC score : 0.933675\n",
            "Accuracy on public test: 0.950000\n",
            "Accuracy on private test: 0.949640\n",
            "Public AUC score : 0.932148\n",
            "Private AUC score : 0.931730\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buFFQpFCRorn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e582174d-0537-4961-d402-2b63808074a8"
      },
      "source": [
        "PATH = '/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/models/gpt2/gpt2-with-max-avg-pool/'\n",
        "versions = sorted(os.listdir(PATH))\n",
        "for version in versions[:4]:\n",
        "  y_public_pred ,y_private_pred =  get_predictions(os.path.join(PATH,version))\n",
        "  evaluate(y_public_pred,y_private_pred, test_public_df, test_private_df,'gpt2/gpt2-with-max-avg-pool/' + version, version )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on public test: 0.951295\n",
            "Accuracy on private test: 0.951387\n",
            "Public AUC score : 0.929758\n",
            "Private AUC score : 0.932254\n",
            "Accuracy on public test: 0.952209\n",
            "Accuracy on private test: 0.952035\n",
            "Public AUC score : 0.931722\n",
            "Private AUC score : 0.933818\n",
            "Accuracy on public test: 0.953853\n",
            "Accuracy on private test: 0.953596\n",
            "Public AUC score : 0.932239\n",
            "Private AUC score : 0.933919\n",
            "Accuracy on public test: 0.952117\n",
            "Accuracy on private test: 0.952610\n",
            "Public AUC score : 0.931196\n",
            "Private AUC score : 0.933628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr13o8p3aYTP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "cb41207c-131c-46f0-bb37-eaa4f11a7665"
      },
      "source": [
        "PATH = '/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/models/BiLSTM/'\n",
        "versions = sorted(os.listdir(PATH))\n",
        "for version in versions:\n",
        "  y_public_pred ,y_private_pred =  get_predictions(os.path.join(PATH,version))\n",
        "  evaluate(y_public_pred,y_private_pred, test_public_df, test_private_df,'BiLSTM/' + version, version )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on public test: 0.952178\n",
            "Accuracy on private test: 0.952353\n",
            "Public AUC score : 0.933871\n",
            "Private AUC score : 0.933306\n",
            "Accuracy on public test: 0.952713\n",
            "Accuracy on private test: 0.952805\n",
            "Public AUC score : 0.932523\n",
            "Private AUC score : 0.933483\n",
            "Accuracy on public test: 0.952569\n",
            "Accuracy on private test: 0.953175\n",
            "Public AUC score : 0.932670\n",
            "Private AUC score : 0.934292\n",
            "Accuracy on public test: 0.952466\n",
            "Accuracy on private test: 0.953011\n",
            "Public AUC score : 0.933524\n",
            "Private AUC score : 0.933870\n",
            "Accuracy on public test: 0.953309\n",
            "Accuracy on private test: 0.953576\n",
            "Public AUC score : 0.934038\n",
            "Private AUC score : 0.933708\n",
            "Accuracy on public test: 0.953761\n",
            "Accuracy on private test: 0.953956\n",
            "Public AUC score : 0.933292\n",
            "Private AUC score : 0.933911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As-A-gbY86a3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "fd8922f9-58c1-43c5-8f62-19d3b0874e3f"
      },
      "source": [
        "PATH = '/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/models/BiGRU/'\n",
        "versions = sorted(os.listdir(PATH))\n",
        "for version in versions:\n",
        "  y_public_pred ,y_private_pred =  get_predictions(os.path.join(PATH,version))\n",
        "  evaluate(y_public_pred,y_private_pred, test_public_df, test_private_df,'BiGRU/' + version, version )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on public test: 0.953319\n",
            "Accuracy on private test: 0.953709\n",
            "Public AUC score : 0.931657\n",
            "Private AUC score : 0.933297\n",
            "Accuracy on public test: 0.952517\n",
            "Accuracy on private test: 0.953216\n",
            "Public AUC score : 0.932302\n",
            "Private AUC score : 0.933735\n",
            "Accuracy on public test: 0.952867\n",
            "Accuracy on private test: 0.952826\n",
            "Public AUC score : 0.931835\n",
            "Private AUC score : 0.933757\n",
            "Accuracy on public test: 0.952867\n",
            "Accuracy on private test: 0.952826\n",
            "Public AUC score : 0.931684\n",
            "Private AUC score : 0.933752\n",
            "Accuracy on public test: 0.953072\n",
            "Accuracy on private test: 0.953052\n",
            "Public AUC score : 0.933233\n",
            "Private AUC score : 0.933193\n",
            "Accuracy on public test: 0.953257\n",
            "Accuracy on private test: 0.953083\n",
            "Public AUC score : 0.933873\n",
            "Private AUC score : 0.933094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehXanAUX-J1x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "03c74f96-bbe3-405d-f5c7-69dfa23f12f0"
      },
      "source": [
        "PATH = '/content/drive/My Drive/Jigsaw Unintended Bias in Toxicity Classification/models/TextCNN/'\n",
        "versions = sorted(os.listdir(PATH))\n",
        "version = versions[1]\n",
        "y_public_pred ,y_private_pred =  get_predictions(os.path.join(PATH,version))\n",
        "evaluate(y_public_pred,y_private_pred, test_public_df, test_private_df,'TextCNN/' + version, version )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on public test: 0.948531\n",
            "Accuracy on private test: 0.948736\n",
            "Public AUC score : 0.912575\n",
            "Private AUC score : 0.916142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vdTB1rR-VEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}